# AI Knowledge Assistant (Local RAG)

A **local Retrieval-Augmented Generation (RAG)** system that lets you query your organizationâ€™s internal policies, procedures, and documents **entirely offline** â€” without any OpenAI or cloud dependency.

Built using **Python, scikit-learn, FAISS/NearestNeighbors, and Streamlit**, it indexes your Markdown, TXT, and PDF files into searchable semantic vectors and retrieves the most relevant text snippets when you ask a question.

---

## ğŸ§© Tech Stack

| Layer | Library / Tool | Purpose |
|-------|-----------------|----------|
| Frontend | [Streamlit](https://streamlit.io) | Interactive chat UI |
| Retrieval | [scikit-learn](https://scikit-learn.org) | TF-IDF + NearestNeighbors search |
| Indexing | NumPy, pandas | Data structures & persistence |
| Dimensionality Reduction | TruncatedSVD | Optional compression of TF-IDF vectors |
| Storage | Pickle | Saves vector index (`storage/*.pkl`) |
| Parsing | [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/) (for PDFs) | Text extraction |

---

AI-Knowledge-Assistant-for-Internal-Docs/
â”œâ”€â”€ app_streamlit.py                 # Streamlit front-end app
â”‚
â”œâ”€â”€ scripts/                         # Indexing and evaluation scripts
â”‚   â”œâ”€â”€ build_index_sklearn_chunks.py   # Builds chunked TF-IDF index
â”‚   â”œâ”€â”€ build_offline_index_tfidf.py    # Builds full-document TF-IDF index
â”‚   â””â”€â”€ evaluate_ragas.py               # (optional) evaluation tools
â”‚
â”œâ”€â”€ rag/                              # RAG utility modules (splitting, prompts, etc.)
â”‚   â”œâ”€â”€ splitter.py
â”‚   â”œâ”€â”€ chain.py
â”‚   â”œâ”€â”€ loaders.py
â”‚   â””â”€â”€ re_rank.py
â”‚
â”œâ”€â”€ data/                             # Source documents (.txt, .md, .pdf)
â”œâ”€â”€ storage/                          # Saved TF-IDF/SVD/NN indexes
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/AI-Knowledge-Assistant-for-Internal-Docs.git
cd AI-Knowledge-Assistant-for-Internal-Docs

2. Create and activate a conda or virtual environment

conda create -n rag-local python=3.11 -y
conda activate rag-local

3. Install dependencies

pip install -r requirements.txt

If you face NumPy/FAISS compatibility issues on Apple Silicon, use:

conda install -c conda-forge numpy==1.26.4 faiss-cpu scikit-learn==1.4.2 pandas==2.2.2


â¸»

ğŸ—‚ï¸ Add Your Documents

Place all your .txt, .md, or .pdf files in the data/ folder.
Example:

data/
â”œâ”€â”€ password_policy.txt
â”œâ”€â”€ security_guidelines.md
â””â”€â”€ blueorbit_security.pdf

Each file should contain human-readable text (no binary or encrypted PDFs).

â¸»

ğŸ”§ Build the Index

Run one of the following to create your search index:

Full document-level index:

python scripts/build_offline_index_tfidf.py

Chunked index (recommended for large files):

python scripts/build_index_sklearn_chunks.py

This generates:

storage/
â”œâ”€â”€ nn_index.pkl         # Full-document index
â””â”€â”€ nn_chunks.pkl        # Chunked index (preferred)


â¸»

ğŸ’¬ Run the Streamlit App

Launch the local UI:

streamlit run app_streamlit.py

Then open the app in your browser (usually http://localhost:8501ï¿¼).

â¸»

ğŸ•µï¸ Query Examples

Once the index is loaded, you can ask natural-language questions like:
	â€¢	â€œWhat is our password policy?â€
	â€¢	â€œHow often should VPN credentials be changed?â€
	â€¢	â€œWho manages access keys?â€
	â€¢	â€œWhat is the clean desk policy?â€
	â€¢	â€œSummarize our data protection policy.â€

The assistant will retrieve the most relevant snippets from your documents and show the answer with source file names.

â¸»

ğŸ§  How It Works
	1.	Text Extraction: All files in data/ are read (PDFs parsed with PyMuPDF).
	2.	Chunking: Large documents are split into overlapping text chunks for granular retrieval.
	3.	Vectorization: TF-IDF transforms each chunk into a sparse vector.
	4.	(Optional) SVD compresses the TF-IDF matrix for faster search.
	5.	NearestNeighbors Search: Queries are embedded using the same TF-IDF model and compared against the stored vectors to find semantically similar chunks.
	6.	Context Display: The top results and their source files are displayed in Streamlit.

â¸»

ğŸ§© Troubleshooting

Issue	Fix
Streamlit app hangs at â€œSolving environmentâ€	Use conda-forge channel for installs
faiss import fails	Try conda install -c conda-forge faiss-cpu
App shows â€œIndex is emptyâ€	Run python scripts/build_index_sklearn_chunks.py again
Mac M3 / ARM issues	Ensure numpy<2.0 and rebuild index


â¸»

ğŸ§­ Roadmap
	â€¢	Add LLM-based summarization via local Ollama or OpenAI API
	â€¢	Implement question-answer reasoning beyond keyword retrieval
	â€¢	Add document re-ranking using embeddings (SentenceTransformers)
	â€¢	Support for Docx / HTML / CSV ingestion

â¸»

ğŸ“„ License

MIT License Â© 2025

â¸»

ğŸŒŸ Acknowledgements

This project uses open-source components from:
	â€¢	Streamlitï¿¼
	â€¢	scikit-learnï¿¼
	â€¢	FAISSï¿¼
	â€¢	PyMuPDFï¿¼
	â€¢	LangChain community examplesï¿¼

---
